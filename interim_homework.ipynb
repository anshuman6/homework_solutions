{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS FILE WILL TAKE around 10 MINUTES TO COMPILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VECTOR CLASS IMPLEMENTATION NOT DONE YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Read all the text files\n",
    "with open(\"/users/anshumangupta/Homework1/data/The Tempest.txt\") as fd1:\n",
    "    tempest_text = fd1.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the text files\n",
    "with open(\"/users/anshumangupta/Homework1/data/Romeo and Juliet.txt\") as fd2:\n",
    "    rj_text = fd2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the text files\n",
    "with open(\"/users/anshumangupta/Homework1/data/The Merchant of Venice.txt\") as fd3:\n",
    "    venice_text = fd3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the text files\n",
    "with open(\"/users/anshumangupta/Homework1/data/Hamlet.txt\") as fd4:\n",
    "    hamlet_text = fd4.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the text files\n",
    "with open(\"/users/anshumangupta/Homework1/data/A Midsummer Night's Dream.txt\") as fd5:\n",
    "    midsum_text = fd5.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps will focus on breaking into words and cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove stopwords using inbuilt function from nltk library\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# List of elizabethan stopwords taken from here: https://bryanbumgardner.com/elizabethan-stop-words-for-nlp/\n",
    "# These new stop words have been updated in the stopwords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(file_data):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    # Splitting the text by space\n",
    "    words_temp_text = file_data\n",
    "    words_temp_text1 = words_temp_text.split()\n",
    "    #print(\"total len:\",len(words_temp_text1))\n",
    "    # Change everything to lower case\n",
    "    words_temp_text_lower = [elem.lower() for elem in words_temp_text1]\n",
    "    #print(\"total lower len:\",len(words_temp_text_lower))\n",
    "    # Strip\n",
    "    words_temp_strip = [elem1.strip() for elem1 in words_temp_text_lower]\n",
    "    #print(\"total strip len:\",len(words_temp_strip))\n",
    "    # Drop last s\n",
    "    words_temp_strip_s1 = [elemx for elemx in words_temp_strip if elemx[-1] != \"s\"]\n",
    "    words_temp_strip_s2 = [elemy[:len(elemy)-1] for elemy in words_temp_strip if elemy[-1] == \"s\"]\n",
    "    words_temp_strip_s1.extend(words_temp_strip_s1)\n",
    "    #print(\"total s drop len:\",len(words_temp_strip))\n",
    "    # Remove stopwords\n",
    "    words_temp_final = [elemz for elemz in words_temp_strip_s1 if elemz not in stop_words]\n",
    "    #print(\"total after stopwords len:\",len(words_temp_final))\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words_to_use = [w.translate(table) for w in words_temp_final]\n",
    "    #print(\"total after all len:\",len(words_temp_final))\n",
    "    return words_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tempest = clean_text(tempest_text)\n",
    "cleaned_rj = clean_text(rj_text)\n",
    "cleaned_venice = clean_text(venice_text)\n",
    "cleaned_hamlet = clean_text(hamlet_text)\n",
    "cleaned_midsum = clean_text(midsum_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a set of words\n",
    "def set_words(ref_lst):\n",
    "    ref_lst1 = ref_lst\n",
    "    set1 = set()\n",
    "    for elem2 in ref_lst1:\n",
    "        if elem2 in set1:\n",
    "            pass\n",
    "        else:\n",
    "            set1.add(elem2)\n",
    "    return set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tempest = set_words(cleaned_tempest)\n",
    "set_rj = set_words(cleaned_rj)\n",
    "set_hamlet = set_words(cleaned_hamlet)\n",
    "set_venice = set_words(cleaned_venice)\n",
    "set_midsum = set_words(cleaned_midsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_all = set_tempest.union(set_rj, set_hamlet, set_venice, set_midsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_list = list(union_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a vector, same dimensions \n",
    "def vecs(lst_to_vec):\n",
    "    lst_to_vec1 = lst_to_vec\n",
    "    #print(lst_to_vec1)\n",
    "    #print(len(lst_to_vec1))\n",
    "    main_vec = np.zeros(len(union_list), dtype = int)\n",
    "    #print(main_vec)\n",
    "    for i in range(len(union_list)):\n",
    "        for j in range(len(lst_to_vec1)):\n",
    "            if lst_to_vec1[j] == union_list[i]:\n",
    "                main_vec[i] += 1\n",
    "    #print(main_vec)\n",
    "    return main_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tempest = vecs(cleaned_tempest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_rj = vecs(cleaned_rj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_hamlet = vecs(cleaned_hamlet)\n",
    "vec_venice = vecs(cleaned_venice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_midsum = vecs(cleaned_midsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32995683904394574\n",
      "0.28675907778325527\n",
      "0.381014962676081\n",
      "1.0000000000000002\n",
      "0.3617662920896585\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(vec_tempest, vec_rj)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_tempest, vec_hamlet)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_hamlet))))\n",
    "print(np.dot(vec_tempest, vec_venice)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_venice))))\n",
    "print(np.dot(vec_tempest, vec_tempest)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_tempest))))\n",
    "print(np.dot(vec_tempest, vec_midsum)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_midsum))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32995683904394574\n",
      "0.4332501084909256\n",
      "0.2789928113917102\n",
      "0.9999999999999999\n",
      "0.44789651850628714\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(vec_tempest, vec_rj)/((np.linalg.norm(vec_tempest))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_venice, vec_rj)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_hamlet, vec_rj)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_rj, vec_rj)/((np.linalg.norm(vec_rj))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_midsum, vec_rj)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_rj))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33237605423779815\n",
      "0.4332501084909256\n",
      "0.381014962676081\n",
      "1.0\n",
      "0.4646048373068697\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(vec_venice, vec_hamlet)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_hamlet))))\n",
    "print(np.dot(vec_venice, vec_rj)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_venice, vec_tempest)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_tempest))))\n",
    "print(np.dot(vec_venice, vec_venice)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_venice))))\n",
    "print(np.dot(vec_venice, vec_midsum)/((np.linalg.norm(vec_venice))*(np.linalg.norm(vec_midsum))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.2789928113917102\n",
      "0.28675907778325527\n",
      "0.33237605423779815\n",
      "0.3070852533049582\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(vec_hamlet, vec_hamlet)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_hamlet))))\n",
    "print(np.dot(vec_hamlet, vec_rj)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_hamlet, vec_tempest)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_tempest))))\n",
    "print(np.dot(vec_hamlet, vec_venice)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_venice))))\n",
    "print(np.dot(vec_hamlet, vec_midsum)/((np.linalg.norm(vec_hamlet))*(np.linalg.norm(vec_midsum))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3070852533049582\n",
      "0.44789651850628714\n",
      "0.3617662920896585\n",
      "0.4646048373068697\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(vec_midsum, vec_hamlet)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_hamlet))))\n",
    "print(np.dot(vec_midsum, vec_rj)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_rj))))\n",
    "print(np.dot(vec_midsum, vec_tempest)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_tempest))))\n",
    "print(np.dot(vec_midsum, vec_venice)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_venice))))\n",
    "print(np.dot(vec_midsum, vec_midsum)/((np.linalg.norm(vec_midsum))*(np.linalg.norm(vec_midsum))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
